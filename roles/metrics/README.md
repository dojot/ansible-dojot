# Observability Stack - Kubernetes

## About

This readme contains the steps for deploying [`Prometheus`](https://prometheus.io/) monitoring application, [`Loki`](https://grafana.com/oss/loki/) to aggregation logs, [`Promtail`] ('https://grafana.com/docs/loki/latest/clients/promtail/') agent which ships the contents of local logs to a private Grafana Loki instance or Grafana Cloud and [`Grafana`](https://grafana.com/grafana/) which is used for visualize and analyze metrics and logs generated by Prometheus and Loki.

## Disclaimer

With a focus on improving the service, aiming at greater maintainability and programmability of the solution. We started a refactoring of the service using [`Helm`](https://helm.sh/), initially we are porting grafana and then we will porte all the rest of the observability solution.

As the inclusion of services (Prometheus, Loki, Promtail and Grafana) is under development, some services are currently not being monitored. The following describes the services already implemented.

## Node Exporter

[`Node Exporter`](https://github.com/prometheus/node_exporter) is used for get host metrics from the host itself. In other words, the metrics obtained by Prometheus are directly related to hardware and operating system.

Available metrics:

* Service uptime;
* Number of CPU cores;
* Total amount of RAM;
* Total amount of containers;
* Disk usage percentage;
* RAM usage percentage;
* Total amount of SWAP;
* Network traffic (Sent and Received);
* CPU usage percentage;
* Total, free and avaliable RAM;
* Amount of RAM for I/O processes;
* Used space of available disks.

## cAdvisor

[`cAdvisor`](https://github.com/google/cadvisor) is an exporter developed by Google that provides metrics regarding resource usage and performance characteristics of running containers.

Available metrics:

* Current status of the container: ``Running``, ``Stopped`` and ``Paused``;
* Network traffic received by container;
* Network traffic sent by container;
* Percentage of RAM usage per container;
* Percentage of CPU usage per container;
* RSS Memory Usage per Container;
* RAM consumption table per container;
* Available RAM for each conatainer;
* RAM limit established for each container.

## For Kubernetes

For [`Kubernetes`](https://kubernetes.io/) we have several specific dashboards for monitoring the cluster, nodes, pods and others services, as mentioned below:

* k8s resources namespaces workloads;
* Dojot 100K;
* Locust;
* Vmq cluster;
* Vmq Nodes;
* k8s resources cluster;
* k8s resources namespaces pods;
* k8s resources namespaces pods;
* k8s resources workloads;
* k8s nodes;
* k8s persistent volumes;
* k8s pods;
* k8s statefulsets;
* k8s usemethod cluster;
* k8s usemethod node.

## Apache Kafka Exporter

Kafka-Exporter is used to get metrics from the service ``Kafka``. In other words, the metrics obtained by Prometheus are directly related to high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.

Available metrics:

* Message in per second;
* Lag by Consumer Group;
* Message in per minute;
* Message consume per minute;
* Partitions per Topic.

## VerneMQ

As ``VerneMQ`` officially enables integration, the process becomes simpler. It is only necessary to declare the ``job`` in the Prometheus configuration file.

Available metrics:

* Summary;
* Clients;
* Queues;
* Subscriptions;
* Erlang VM;
* Bytes IN & OUT;
* Retain;
* TCP Sockets;
* Node to cluster communication;
* MQTT Connect;
* MQTT Subscribe;
* MQTT Publish;
* MQTT Ping;
* MISC.

## Kong API Gateway Exporter

As ``Kong`` officially allows the integration, the process becomes simpler. It is only necessary to declare ``job`` in the Prometheus configuration file to get metrics regarding cloud services to manage, monitor and scale application programming interfaces and microservices.

Available metrics:

* Status codes;
* Latencies Histograms;
  * Request;
  * Kong;
  * Upstream;
* Bandwidth;
* DB reachability;
* Connections;
* Target Health;
* Dataplane Status;
* Enterprise License Information.

## InfluxDB

As ``InfluxDB`` officially allows the integration, the process becomes simpler. It is only necessary to declare ``job`` in the Prometheus configuration file to get metrics regarding cloud services to manage, monitor and scale application programming interfaces and microservices.

Available metrics:

* InfluxDB Informations;
* Request for InfluxDB;
* GO Metrics;

Note: influxdb is not initialized by default, if you want to use and monitor it, it is necessary to enable the service and its dependencies in ``inventories/example_local/group_vars/all/services.yaml``.

## MongoDB Exporter

[`MongoDB Exporter`](https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus-mongodb-exporter) is used to get metrics from ``MongoDB`` service.

Available metrics:

* Query metrics for MongoDB;
* Health metrics for MongoDB;
* Resource Metrics;
* Dashboard Row;

## Postgres Exporter

Postgres-Exporter is used to get metrics from ``Postgres`` service.

Available metrics:

* General Counters, CPU, Memory and File Descriptor Stats
* Settings;
* Database Stats;

## RabbitMQ Exporter

RabbitMQ-Exporter is used to get metrics from ``RabbitMQ`` service.

Available metrics:

* Logs;
* Stream publishers and receiveds;
* Nodes;
* Queue Messages;
* Memory available and outhers;

## How to view and access data in grafana?

* If you are using dojot in a local cluster, just access the grafana service through the URL http://localhost:3000 and prometheus via the URL http://localhost:9090.

* However, if you do not have local access to the cluster, to access the services of prometheus and grafana, simply open an ``SSH`` tunnel using the ``IP`` of the service. To get the ``IP`` of the services run the commands below and search for ``Endpoints`` from the command output:

```
kubectl describe service grafana -n dojot-monitoring
```

and

```
kubectl describe service prometheus-server -n dojot-monitoring
```

* After that, just open an ssh tunnel with the endpoint obtained, for example:

## How to deploy monitoring solution?

Initially, it is necessary to deploy the volumes that will be used by the services to store and obtain log data, metrics and others. So, run the command below to deploy the volumes:

```
ansible-playbook -K -k -u dojot -i inventories/example_local/ volume-monitoring.yaml
```

Now that the volumes are available, we can deploy the monitoring services by running the command below:

```
ansible-playbook -K -k -u dojot -i inventories/example_local/ deploy-monitoring.yaml
```

# Observation

At this moment, the dojot user has the possibility to choose between two storage classes (local-storage and NFS). However, due to the warning provided in the Prometheus documentation regarding the form of storage, Prometheus, in particular, will use local-storage statically, without the possibility of using NFS due to this incompatibility.

Note made in the Prometheus documentation:

``CAUTION``: Non-POSIX compliant filesystems are not supported for Prometheus' local storage as unrecoverable corruptions may happen. NFS filesystems (including AWS's EFS) are not supported. NFS could be POSIX-compliant, but most implementations are not. It is strongly recommended to use a local filesystem for reliability.

# Prometheus

ssh -L <portlocal>:<endpoint_service_prometheus>:9090 <user_cluster>@<ip_cluster>

Example:

ssh -L 9090:10.200.40.100:9090 myuser@11:210.44.110

# Grafana

ssh -L <portlocal>:<endpoint_service_prometheus>:3000 <user_cluster>:<ip_cluster>

Example:

ssh -L 3000:10.200.40.100:3000 myuser@11:210.44.110


# User and password to access grafana

**User**: ``admin``

**Password**: ``admin``